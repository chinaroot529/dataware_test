#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Doris Routine Load é…ç½®è„šæœ¬
ç”¨äºè®¾ç½®ä»Kafkaæ¶ˆè´¹CDCæ•°æ®çš„Routine Loadä»»åŠ¡
"""

import pymysql
import json
import time
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DorisRoutineLoadManager:
    def __init__(self):
        self.doris_config = {
            'host': '192.168.99.6',
            'port': 19030,  # MySQLåè®®ç«¯å£
            'user': 'root',
            'password': '',
            'database': 'ods',
            'charset': 'utf8mb4'
        }
        
        self.kafka_config = {
            'brokers': 'localhost:9092',
            'topic': 'abc_warning',  # è½¬æ¢åçš„topicåç§°
            'group': 'doris_cdc_consumer'
        }
    
    def connect_doris(self):
        """è¿æ¥Dorisæ•°æ®åº“"""
        try:
            conn = pymysql.connect(**self.doris_config)
            logger.info("âœ… Dorisè¿æ¥æˆåŠŸ")
            return conn
        except Exception as e:
            logger.error(f"âŒ Dorisè¿æ¥å¤±è´¥: {e}")
            return None
    
    def create_routine_load_job(self, table_name='abc_warning'):
        """åˆ›å»ºRoutine Loadä»»åŠ¡"""
        conn = self.connect_doris()
        if not conn:
            return False
        
        try:
            cursor = conn.cursor()
            cursor.execute(f"USE {self.doris_config['database']}")
            
            # åœæ­¢å·²å­˜åœ¨çš„åŒåä»»åŠ¡
            try:
                stop_sql = f"STOP ROUTINE LOAD FOR {table_name}_cdc_load"
                cursor.execute(stop_sql)
                logger.info(f"ğŸ›‘ å·²åœæ­¢å­˜åœ¨çš„Routine Loadä»»åŠ¡: {table_name}_cdc_load")
                time.sleep(5)  # ç­‰å¾…ä»»åŠ¡åœæ­¢
            except Exception as e:
                logger.info(f"â„¹ï¸  æ²¡æœ‰éœ€è¦åœæ­¢çš„ä»»åŠ¡: {e}")
            
            # åˆ›å»ºæ–°çš„Routine Loadä»»åŠ¡
            routine_load_sql = f"""
CREATE ROUTINE LOAD {table_name}_cdc_load ON {table_name}
COLUMNS(
    snapshot_date,
    student_id,
    attendance_rate,
    submit_rate,
    violation_cnt,
    core_fail_cnt,
    risk_level,
    __op = jsonb_extract_string(message, '$.op'),
    __ts_ms = jsonb_extract_string(message, '$.ts_ms'),
    __source_db = jsonb_extract_string(message, '$.source_db'),
    __source_table = jsonb_extract_string(message, '$.source_table')
)
PROPERTIES (
    "format" = "json",
    "jsonpaths" = "[
        \\"$.snapshot_date\\",
        \\"$.student_id\\",
        \\"$.attendance_rate\\",
        \\"$.submit_rate\\",
        \\"$.violation_cnt\\",
        \\"$.core_fail_cnt\\",
        \\"$.risk_level\\",
        \\"$\\"
    ]",
    "strip_outer_array" = "false",
    "fuzzy_parse" = "true",
    "max_batch_interval" = "10",
    "max_batch_rows" = "100000",
    "max_batch_size" = "104857600",
    "desired_concurrent_number" = "1",
    "max_error_number" = "100"
)
FROM KAFKA (
    "kafka_broker_list" = "{self.kafka_config['brokers']}",
    "kafka_topic" = "{self.kafka_config['topic']}",
    "property.group.id" = "{self.kafka_config['group']}",
    "property.client.id" = "doris_cdc_client",
    "property.kafka_default_offsets" = "OFFSET_BEGINNING",
    "property.enable.auto.commit" = "true",
    "property.auto.commit.interval.ms" = "5000",
    "property.session.timeout.ms" = "30000",
    "property.request.timeout.ms" = "60000",
    "property.max.poll.records" = "1000"
)
"""
            
            logger.info(f"ğŸš€ æ­£åœ¨åˆ›å»ºRoutine Loadä»»åŠ¡: {table_name}_cdc_load")
            logger.info(f"SQL: {routine_load_sql}")
            
            cursor.execute(routine_load_sql)
            logger.info(f"âœ… Routine Loadä»»åŠ¡åˆ›å»ºæˆåŠŸ: {table_name}_cdc_load")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºRoutine Loadä»»åŠ¡å¤±è´¥: {e}")
            return False
        finally:
            conn.close()
    
    def create_unique_key_table(self, table_name='abc_warning'):
        """åˆ›å»ºæ”¯æŒCDCçš„Unique Keyè¡¨"""
        conn = self.connect_doris()
        if not conn:
            return False
        
        try:
            cursor = conn.cursor()
            cursor.execute(f"USE {self.doris_config['database']}")
            
            # åˆ é™¤å·²å­˜åœ¨çš„è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            try:
                cursor.execute(f"DROP TABLE IF EXISTS {table_name}")
                logger.info(f"ğŸ—‘ï¸  å·²åˆ é™¤å­˜åœ¨çš„è¡¨: {table_name}")
            except Exception as e:
                logger.info(f"â„¹ï¸  è¡¨ä¸å­˜åœ¨æˆ–åˆ é™¤å¤±è´¥: {e}")
            
            # åˆ›å»ºæ”¯æŒCDCçš„Unique Keyè¡¨
            create_table_sql = f"""
CREATE TABLE IF NOT EXISTS {table_name} (
    `snapshot_date` DATE NOT NULL COMMENT "å¿«ç…§æ—¥æœŸ",
    `student_id` VARCHAR(50) NOT NULL COMMENT "å­¦ç”ŸID",
    `attendance_rate` DECIMAL(5,4) COMMENT "å‡ºå‹¤ç‡",
    `submit_rate` DECIMAL(5,4) COMMENT "æäº¤ç‡",
    `violation_cnt` INT COMMENT "è¿è§„æ¬¡æ•°",
    `core_fail_cnt` INT COMMENT "æ ¸å¿ƒè¯¾ç¨‹æŒ‚ç§‘æ¬¡æ•°",
    `risk_level` VARCHAR(20) COMMENT "é£é™©ç­‰çº§",
    `__op` VARCHAR(10) COMMENT "CDCæ“ä½œç±»å‹",
    `__ts_ms` BIGINT COMMENT "CDCæ—¶é—´æˆ³",
    `__source_db` VARCHAR(100) COMMENT "æºæ•°æ®åº“",
    `__source_table` VARCHAR(100) COMMENT "æºè¡¨å",
    `__doris_version_count` BIGINT DEFAULT 1 COMMENT "Dorisç‰ˆæœ¬è®¡æ•°å™¨"
) UNIQUE KEY(`snapshot_date`, `student_id`)
DISTRIBUTED BY HASH(`student_id`) BUCKETS 10
PROPERTIES (
    "replication_allocation" = "tag.location.default: 1",
    "enable_unique_key_merge_on_write" = "true",
    "function_column.sequence_col" = "__doris_version_count",
    "light_schema_change" = "true",
    "store_row_column" = "true"
)
"""
            
            logger.info(f"ğŸ—ï¸  æ­£åœ¨åˆ›å»ºUnique Keyè¡¨: {table_name}")
            cursor.execute(create_table_sql)
            logger.info(f"âœ… Unique Keyè¡¨åˆ›å»ºæˆåŠŸ: {table_name}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºè¡¨å¤±è´¥: {e}")
            return False
        finally:
            conn.close()
    
    def check_routine_load_status(self, table_name='abc_warning'):
        """æ£€æŸ¥Routine Loadä»»åŠ¡çŠ¶æ€"""
        conn = self.connect_doris()
        if not conn:
            return None
        
        try:
            cursor = conn.cursor(pymysql.cursors.DictCursor)
            cursor.execute(f"USE {self.doris_config['database']}")
            
            sql = f"SHOW ROUTINE LOAD FOR {table_name}_cdc_load"
            cursor.execute(sql)
            result = cursor.fetchone()
            
            if result:
                logger.info(f"ğŸ“Š Routine LoadçŠ¶æ€:")
                logger.info(f"   ä»»åŠ¡å: {result.get('Name', 'N/A')}")
                logger.info(f"   çŠ¶æ€: {result.get('State', 'N/A')}")
                logger.info(f"   æ•°æ®æº: {result.get('DataSourceType', 'N/A')}")
                logger.info(f"   è¿›åº¦: {result.get('Progress', 'N/A')}")
                logger.info(f"   åˆ›å»ºæ—¶é—´: {result.get('CreateTime', 'N/A')}")
                logger.info(f"   é”™è¯¯ä¿¡æ¯: {result.get('ReasonOfStateChanged', 'N/A')}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢Routine LoadçŠ¶æ€å¤±è´¥: {e}")
            return None
        finally:
            conn.close()
    
    def pause_routine_load(self, table_name='abc_warning'):
        """æš‚åœRoutine Loadä»»åŠ¡"""
        conn = self.connect_doris()
        if not conn:
            return False
        
        try:
            cursor = conn.cursor()
            cursor.execute(f"USE {self.doris_config['database']}")
            
            sql = f"PAUSE ROUTINE LOAD FOR {table_name}_cdc_load"
            cursor.execute(sql)
            logger.info(f"â¸ï¸  Routine Loadä»»åŠ¡å·²æš‚åœ: {table_name}_cdc_load")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æš‚åœRoutine Loadä»»åŠ¡å¤±è´¥: {e}")
            return False
        finally:
            conn.close()
    
    def resume_routine_load(self, table_name='abc_warning'):
        """æ¢å¤Routine Loadä»»åŠ¡"""
        conn = self.connect_doris()
        if not conn:
            return False
        
        try:
            cursor = conn.cursor()
            cursor.execute(f"USE {self.doris_config['database']}")
            
            sql = f"RESUME ROUTINE LOAD FOR {table_name}_cdc_load"
            cursor.execute(sql)
            logger.info(f"â–¶ï¸  Routine Loadä»»åŠ¡å·²æ¢å¤: {table_name}_cdc_load")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¢å¤Routine Loadä»»åŠ¡å¤±è´¥: {e}")
            return False
        finally:
            conn.close()
    
    def get_load_statistics(self, table_name='abc_warning'):
        """è·å–åŠ è½½ç»Ÿè®¡ä¿¡æ¯"""
        conn = self.connect_doris()
        if not conn:
            return None
        
        try:
            cursor = conn.cursor(pymysql.cursors.DictCursor)
            cursor.execute(f"USE {self.doris_config['database']}")
            
            # è·å–è¡¨è¡Œæ•°
            cursor.execute(f"SELECT COUNT(*) as total_rows FROM {table_name}")
            table_stats = cursor.fetchone()
            
            # è·å–æœ€æ–°CDCæ“ä½œç»Ÿè®¡
            cursor.execute(f"""
                SELECT 
                    __op, 
                    COUNT(*) as count,
                    MAX(__ts_ms) as latest_ts
                FROM {table_name} 
                WHERE __op IS NOT NULL 
                GROUP BY __op
            """)
            op_stats = cursor.fetchall()
            
            return {
                'total_rows': table_stats['total_rows'],
                'operations': op_stats
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return None
        finally:
            conn.close()

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Doris Routine Loadç®¡ç†å·¥å…·')
    parser.add_argument('action', choices=['create-table', 'create-load', 'status', 'pause', 'resume', 'stats'],
                        help='æ‰§è¡Œçš„æ“ä½œ')
    parser.add_argument('--table', default='abc_warning', help='è¡¨å')
    
    args = parser.parse_args()
    
    manager = DorisRoutineLoadManager()
    
    if args.action == 'create-table':
        print("ğŸ—ï¸  åˆ›å»ºUnique Keyè¡¨...")
        if manager.create_unique_key_table(args.table):
            print("âœ… è¡¨åˆ›å»ºæˆåŠŸ!")
        else:
            print("âŒ è¡¨åˆ›å»ºå¤±è´¥!")
    
    elif args.action == 'create-load':
        print("ğŸš€ åˆ›å»ºRoutine Loadä»»åŠ¡...")
        if manager.create_routine_load_job(args.table):
            print("âœ… Routine Loadä»»åŠ¡åˆ›å»ºæˆåŠŸ!")
        else:
            print("âŒ Routine Loadä»»åŠ¡åˆ›å»ºå¤±è´¥!")
    
    elif args.action == 'status':
        print("ğŸ“Š æŸ¥è¯¢Routine LoadçŠ¶æ€...")
        manager.check_routine_load_status(args.table)
    
    elif args.action == 'pause':
        print("â¸ï¸  æš‚åœRoutine Loadä»»åŠ¡...")
        if manager.pause_routine_load(args.table):
            print("âœ… ä»»åŠ¡å·²æš‚åœ!")
        else:
            print("âŒ æš‚åœå¤±è´¥!")
    
    elif args.action == 'resume':
        print("â–¶ï¸  æ¢å¤Routine Loadä»»åŠ¡...")
        if manager.resume_routine_load(args.table):
            print("âœ… ä»»åŠ¡å·²æ¢å¤!")
        else:
            print("âŒ æ¢å¤å¤±è´¥!")
    
    elif args.action == 'stats':
        print("ğŸ“ˆ è·å–åŠ è½½ç»Ÿè®¡...")
        stats = manager.get_load_statistics(args.table)
        if stats:
            print(f"æ€»è¡Œæ•°: {stats['total_rows']}")
            print("æ“ä½œç»Ÿè®¡:")
            for op in stats['operations']:
                print(f"  {op['__op']}: {op['count']} æ¬¡")
        else:
            print("âŒ è·å–ç»Ÿè®¡å¤±è´¥!")

if __name__ == '__main__':
    main() 