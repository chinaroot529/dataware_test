#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº‘ç«¯CDCç³»ç»Ÿéƒ¨ç½²è„šæœ¬
é€‚é…ç°æœ‰Kafkaç¯å¢ƒçš„CDCæµæ°´çº¿éƒ¨ç½²
"""

import requests
import json
import time
import subprocess
import logging
import pymysql
from datetime import datetime, timedelta
from typing import Dict, List, Any

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class CloudCDCManager:
    def __init__(self):
        self.kafka_connect_url = "http://localhost:8083"
        self.kafka_ui_url = "http://localhost:8080"
        self.debezium_ui_url = "http://localhost:8082"
        
        # äº‘ç«¯Kafkaé…ç½®
        self.kafka_broker = "192.168.99.6:9092"
        
        self.doris_config = {
            'host': '192.168.99.6',
            'port': 19030,
            'user': 'root',
            'password': '',
            'database': 'ods',
            'charset': 'utf8mb4'
        }
        
        self.mysql_config = {
            'host': '10.10.0.117',
            'port': 6033,
            'user': 'root',
            'password': 'Xml123&45!',
            'database': 'data_ware_test',
            'charset': 'utf8mb4'
        }
    
    def start_cdc_services(self):
        """å¯åŠ¨CDCæœåŠ¡ï¼ˆä½¿ç”¨äº‘ç«¯é…ç½®ï¼‰"""
        try:
            logger.info("ğŸš€ å¯åŠ¨CDCæœåŠ¡...")
            cmd = ["docker-compose", "-f", "docker-compose.cloud.yml", "up", "-d"]
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=".")
            
            if result.returncode == 0:
                logger.info("âœ… CDCæœåŠ¡å¯åŠ¨æˆåŠŸ!")
                logger.info("ğŸ“‹ æœåŠ¡åœ°å€:")
                logger.info("   Kafka UI: http://192.168.99.6:8080")
                logger.info("   Debezium UI: http://192.168.99.6:8082")
                logger.info("   Kafka Connect API: http://192.168.99.6:8083")
                logger.info("   Prometheus: http://192.168.99.6:9090")
                logger.info("   Grafana: http://192.168.99.6:3000 (admin/admin)")
                
                # ç­‰å¾…æœåŠ¡å¯åŠ¨
                self.wait_for_services()
                return True
            else:
                logger.error(f"âŒ CDCæœåŠ¡å¯åŠ¨å¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨CDCæœåŠ¡æ—¶å‡ºé”™: {e}")
            return False
    
    def stop_cdc_services(self):
        """åœæ­¢CDCæœåŠ¡"""
        try:
            logger.info("ğŸ›‘ åœæ­¢CDCæœåŠ¡...")
            cmd = ["docker-compose", "-f", "docker-compose.cloud.yml", "down"]
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=".")
            
            if result.returncode == 0:
                logger.info("âœ… CDCæœåŠ¡å·²åœæ­¢!")
                return True
            else:
                logger.error(f"âŒ åœæ­¢CDCæœåŠ¡å¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ åœæ­¢CDCæœåŠ¡æ—¶å‡ºé”™: {e}")
            return False
    
    def wait_for_services(self, timeout=300):
        """ç­‰å¾…æœåŠ¡å¯åŠ¨å®Œæˆ"""
        logger.info("â³ ç­‰å¾…æœåŠ¡å¯åŠ¨å®Œæˆ...")
        
        services = {
            "Kafka Connect": "http://localhost:8083",
            "Kafka UI": "http://localhost:8080",
            "Debezium UI": "http://localhost:8082"
        }
        
        start_time = time.time()
        for service_name, url in services.items():
            logger.info(f"ğŸ” ç­‰å¾… {service_name} å¯åŠ¨...")
            while time.time() - start_time < timeout:
                try:
                    response = requests.get(url, timeout=5)
                    if response.status_code == 200:
                        logger.info(f"âœ… {service_name} å·²å¯åŠ¨")
                        break
                except requests.exceptions.RequestException:
                    pass
                time.sleep(5)
            else:
                logger.warning(f"âš ï¸  {service_name} å¯åŠ¨è¶…æ—¶")
        
        logger.info("ğŸ‰ æœåŠ¡å¯åŠ¨å®Œæˆ!")
    
    def deploy_mysql_connector(self):
        """éƒ¨ç½²MySQL CDCè¿æ¥å™¨ï¼ˆäº‘ç«¯ç‰ˆæœ¬ï¼‰"""
        try:
            # è¯»å–äº‘ç«¯è¿æ¥å™¨é…ç½®
            with open('config/mysql-connector-cloud.json', 'r') as f:
                connector_config = json.load(f)
            
            # å‘é€åˆ°Kafka Connect
            url = f"{self.kafka_connect_url}/connectors"
            headers = {"Content-Type": "application/json"}
            
            logger.info("ğŸ”— éƒ¨ç½²MySQL CDCè¿æ¥å™¨...")
            response = requests.post(url, headers=headers, json=connector_config)
            
            if response.status_code in [200, 201]:
                logger.info("âœ… MySQL CDCè¿æ¥å™¨éƒ¨ç½²æˆåŠŸ!")
                return True
            else:
                logger.error(f"âŒ MySQL CDCè¿æ¥å™¨éƒ¨ç½²å¤±è´¥: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ éƒ¨ç½²MySQL CDCè¿æ¥å™¨æ—¶å‡ºé”™: {e}")
            return False
    
    def check_kafka_connection(self):
        """æ£€æŸ¥Kafkaè¿æ¥"""
        try:
            # ä½¿ç”¨docker execæ£€æŸ¥Kafkaä¸»é¢˜
            cmd = [
                "docker", "exec", "-i", "kafka-connect",
                "kafka-topics", "--bootstrap-server", self.kafka_broker, "--list"
            ]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                topics = result.stdout.strip().split('\n')
                logger.info(f"ğŸ“‹ Kafkaä¸»é¢˜ ({self.kafka_broker}): {topics}")
                return True
            else:
                logger.error(f"âŒ è¿æ¥Kafkaå¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥Kafkaè¿æ¥æ—¶å‡ºé”™: {e}")
            return False
    
    def create_doris_routine_load(self):
        """åˆ›å»ºDoris Routine Loadï¼ˆä½¿ç”¨äº‘ç«¯Kafkaï¼‰"""
        try:
            conn = pymysql.connect(**self.doris_config)
            cursor = conn.cursor()
            cursor.execute(f"USE {self.doris_config['database']}")
            
            # åœæ­¢å·²å­˜åœ¨çš„åŒåä»»åŠ¡
            try:
                stop_sql = "STOP ROUTINE LOAD FOR abc_warning_cdc_load"
                cursor.execute(stop_sql)
                logger.info("ğŸ›‘ å·²åœæ­¢å­˜åœ¨çš„Routine Loadä»»åŠ¡")
                time.sleep(5)
            except Exception as e:
                logger.info(f"â„¹ï¸  æ²¡æœ‰éœ€è¦åœæ­¢çš„ä»»åŠ¡: {e}")
            
            # åˆ›å»ºæ–°çš„Routine Loadä»»åŠ¡ï¼ˆä½¿ç”¨äº‘ç«¯Kafkaåœ°å€ï¼‰
            routine_load_sql = f"""
CREATE ROUTINE LOAD abc_warning_cdc_load ON abc_warning
COLUMNS(
    snapshot_date,
    student_id,
    attendance_rate,
    submit_rate,
    violation_cnt,
    core_fail_cnt,
    risk_level,
    __op = jsonb_extract_string(message, '$.op'),
    __ts_ms = jsonb_extract_string(message, '$.ts_ms'),
    __source_db = jsonb_extract_string(message, '$.source_db'),
    __source_table = jsonb_extract_string(message, '$.source_table')
)
PROPERTIES (
    "format" = "json",
    "jsonpaths" = "[
        \\"$.snapshot_date\\",
        \\"$.student_id\\",
        \\"$.attendance_rate\\",
        \\"$.submit_rate\\",
        \\"$.violation_cnt\\",
        \\"$.core_fail_cnt\\",
        \\"$.risk_level\\",
        \\"$\\"
    ]",
    "strip_outer_array" = "false",
    "fuzzy_parse" = "true",
    "max_batch_interval" = "10",
    "max_batch_rows" = "100000",
    "max_batch_size" = "104857600",
    "desired_concurrent_number" = "1",
    "max_error_number" = "100"
)
FROM KAFKA (
    "kafka_broker_list" = "{self.kafka_broker}",
    "kafka_topic" = "abc_warning",
    "property.group.id" = "doris_cdc_consumer",
    "property.client.id" = "doris_cdc_client",
    "property.kafka_default_offsets" = "OFFSET_BEGINNING",
    "property.enable.auto.commit" = "true",
    "property.auto.commit.interval.ms" = "5000",
    "property.session.timeout.ms" = "30000",
    "property.request.timeout.ms" = "60000",
    "property.max.poll.records" = "1000"
)
"""
            
            logger.info("ğŸš€ æ­£åœ¨åˆ›å»ºRoutine Loadä»»åŠ¡...")
            cursor.execute(routine_load_sql)
            logger.info("âœ… Routine Loadä»»åŠ¡åˆ›å»ºæˆåŠŸ!")
            
            cursor.close()
            conn.close()
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºRoutine Loadä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def health_check(self):
        """å¥åº·æ£€æŸ¥"""
        logger.info("ğŸ¥ CDCæµæ°´çº¿å¥åº·æ£€æŸ¥")
        
        health_status = {
            'kafka_connection': False,
            'kafka_connect': False,
            'connector': False,
            'doris_connection': False
        }
        
        # æ£€æŸ¥Kafkaè¿æ¥
        health_status['kafka_connection'] = self.check_kafka_connection()
        
        # æ£€æŸ¥Kafka Connect
        try:
            response = requests.get(f"{self.kafka_connect_url}/connectors")
            health_status['kafka_connect'] = response.status_code == 200
        except:
            pass
        
        # æ£€æŸ¥è¿æ¥å™¨çŠ¶æ€
        try:
            response = requests.get(f"{self.kafka_connect_url}/connectors")
            if response.status_code == 200:
                connectors = response.json()
                health_status['connector'] = len(connectors) > 0
        except:
            pass
        
        # æ£€æŸ¥Dorisè¿æ¥
        try:
            conn = pymysql.connect(**self.doris_config)
            conn.close()
            health_status['doris_connection'] = True
        except:
            pass
        
        # æ‰“å°å¥åº·æ£€æŸ¥ç»“æœ
        logger.info("ğŸ¯ å¥åº·æ£€æŸ¥ç»“æœ:")
        for component, status in health_status.items():
            status_icon = "âœ…" if status else "âŒ"
            logger.info(f"   {component}: {status_icon}")
        
        return health_status

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='äº‘ç«¯CDCç®¡ç†å·¥å…·')
    parser.add_argument('action', choices=[
        'start', 'stop', 'deploy-connector', 'create-routine-load', 'health', 'check-kafka'
    ], help='æ‰§è¡Œçš„æ“ä½œ')
    
    args = parser.parse_args()
    manager = CloudCDCManager()
    
    if args.action == 'start':
        print("ğŸš€ å¯åŠ¨CDCæœåŠ¡...")
        if manager.start_cdc_services():
            print("âœ… CDCæœåŠ¡å¯åŠ¨æˆåŠŸ!")
        else:
            print("âŒ CDCæœåŠ¡å¯åŠ¨å¤±è´¥!")
    
    elif args.action == 'stop':
        print("ğŸ›‘ åœæ­¢CDCæœåŠ¡...")
        if manager.stop_cdc_services():
            print("âœ… CDCæœåŠ¡å·²åœæ­¢!")
        else:
            print("âŒ CDCæœåŠ¡åœæ­¢å¤±è´¥!")
    
    elif args.action == 'deploy-connector':
        print("ğŸ”— éƒ¨ç½²MySQL CDCè¿æ¥å™¨...")
        if manager.deploy_mysql_connector():
            print("âœ… MySQL CDCè¿æ¥å™¨éƒ¨ç½²æˆåŠŸ!")
        else:
            print("âŒ MySQL CDCè¿æ¥å™¨éƒ¨ç½²å¤±è´¥!")
    
    elif args.action == 'create-routine-load':
        print("ğŸš€ åˆ›å»ºDoris Routine Load...")
        if manager.create_doris_routine_load():
            print("âœ… Routine Loadåˆ›å»ºæˆåŠŸ!")
        else:
            print("âŒ Routine Loadåˆ›å»ºå¤±è´¥!")
    
    elif args.action == 'health':
        print("ğŸ¥ CDCæµæ°´çº¿å¥åº·æ£€æŸ¥...")
        manager.health_check()
    
    elif args.action == 'check-kafka':
        print("ğŸ“‹ æ£€æŸ¥Kafkaè¿æ¥...")
        manager.check_kafka_connection()

if __name__ == '__main__':
    main() 