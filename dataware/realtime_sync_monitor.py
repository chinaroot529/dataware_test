#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœŸæ­£çš„å®æ—¶åŒæ­¥ç›‘æ§å™¨ - MySQLåˆ°Doris
å®ç°æ¯«ç§’çº§çš„å®æ—¶æ•°æ®åŒæ­¥ï¼ŒæŒç»­ç›‘æ§MySQLå˜åŒ–
"""

import time
import threading
import logging
import json
from datetime import datetime, timedelta
import pymysql
from typing import Set, Dict, Any

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/tmp/realtime_sync.log'),
        logging.StreamHandler()
    ]
)

class RealtimeSyncMonitor:
    def __init__(self, check_interval=1):  # 1ç§’æ£€æŸ¥ä¸€æ¬¡
        self.check_interval = check_interval
        self.last_max_id = None
        self.last_update_time = None
        self.running = False
        
        # MySQLæºæ•°æ®åº“é…ç½®
        self.mysql_config = {
            'host': '10.10.0.117',
            'port': 6033,
            'user': 'root',
            'password': 'Xml123&45!',
            'database': 'data_ware_test',
            'charset': 'utf8mb4',
            'autocommit': True
        }
        
        # Dorisç›®æ ‡æ•°æ®åº“é…ç½®
        self.doris_config = {
            'host': '192.168.99.6',
            'port': 19030,
            'user': 'root',
            'password': '',
            'database': 'ods',
            'charset': 'utf8mb4',
            'autocommit': True
        }
    
    def get_mysql_connection(self):
        """è·å–MySQLè¿æ¥"""
        return pymysql.connect(**self.mysql_config)
    
    def get_doris_connection(self):
        """è·å–Dorisè¿æ¥"""
        return pymysql.connect(**self.doris_config)
    
    def get_mysql_latest_records(self, since_time=None):
        """è·å–MySQLæœ€æ–°è®°å½•"""
        try:
            conn = self.get_mysql_connection()
            cursor = conn.cursor(pymysql.cursors.DictCursor)
            
            if since_time:
                # åŸºäºæ—¶é—´æˆ³çš„å¢é‡æŸ¥è¯¢
                sql = """
                SELECT * FROM abc_warning 
                WHERE snapshot_date >= %s
                ORDER BY snapshot_date DESC, student_id DESC
                """
                cursor.execute(sql, (since_time,))
            else:
                # è·å–æœ€æ–°çš„è®°å½•
                sql = """
                SELECT * FROM abc_warning 
                ORDER BY snapshot_date DESC, student_id DESC 
                LIMIT 100
                """
                cursor.execute(sql)
            
            records = cursor.fetchall()
            cursor.close()
            conn.close()
            return records
        except Exception as e:
            logging.error(f"è·å–MySQLè®°å½•å¤±è´¥: {e}")
            return []
    
    def get_doris_latest_timestamp(self):
        """è·å–Dorisä¸­æœ€æ–°çš„æ—¶é—´æˆ³"""
        try:
            conn = self.get_doris_connection()
            cursor = conn.cursor(pymysql.cursors.DictCursor)
            
            sql = "SELECT MAX(snapshot_date) as max_date FROM abc_warning"
            cursor.execute(sql)
            result = cursor.fetchone()
            cursor.close()
            conn.close()
            
            return result['max_date'] if result and result['max_date'] else None
        except Exception as e:
            logging.error(f"è·å–Dorisæœ€æ–°æ—¶é—´æˆ³å¤±è´¥: {e}")
            return None
    
    def sync_records_to_doris(self, records):
        """å°†è®°å½•åŒæ­¥åˆ°Doris"""
        if not records:
            return True
            
        try:
            conn = self.get_doris_connection()
            cursor = conn.cursor()
            
            # æ‰¹é‡æ’å…¥è®°å½•
            insert_sql = """
            INSERT INTO abc_warning 
            (snapshot_date, student_id, attendance_rate, submit_rate, violation_cnt, core_fail_cnt, risk_level)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            """
            
            sync_count = 0
            for record in records:
                try:
                    cursor.execute(insert_sql, (
                        record['snapshot_date'],
                        record['student_id'],
                        record['attendance_rate'],
                        record['submit_rate'],
                        record['violation_cnt'],
                        record['core_fail_cnt'],
                        record['risk_level']
                    ))
                    sync_count += 1
                except Exception as e:
                    # å¦‚æœæ˜¯é‡å¤è®°å½•ï¼Œè·³è¿‡
                    if "Duplicate entry" in str(e):
                        continue
                    else:
                        logging.error(f"æ’å…¥è®°å½•å¤±è´¥: {e}")
            
            cursor.close()
            conn.close()
            
            if sync_count > 0:
                logging.info(f"âœ… æˆåŠŸåŒæ­¥ {sync_count} æ¡è®°å½•åˆ°Doris")
            
            return True
        except Exception as e:
            logging.error(f"åŒæ­¥åˆ°Doriså¤±è´¥: {e}")
            return False
    
    def detect_new_data(self):
        """æ£€æµ‹æ–°æ•°æ®"""
        try:
            # è·å–Dorisä¸­æœ€æ–°çš„æ—¥æœŸ
            doris_latest_date = self.get_doris_latest_timestamp()
            
            # ä»MySQLè·å–å¯èƒ½çš„æ–°æ•°æ®
            if doris_latest_date:
                # ä»æœ€æ–°æ—¥æœŸå¼€å§‹æŸ¥æ‰¾
                since_date = doris_latest_date
            else:
                # å¦‚æœDorisæ˜¯ç©ºçš„ï¼Œè·å–MySQLæœ€è¿‘1å°æ—¶çš„æ•°æ®
                since_date = (datetime.now() - timedelta(hours=1)).date()
            
            new_records = self.get_mysql_latest_records(since_date)
            
            if new_records:
                # è·å–Dorisç°æœ‰çš„è®°å½•ï¼Œç”¨äºå»é‡
                doris_records = self.get_doris_records_for_date(since_date)
                doris_keys = {(r['snapshot_date'], r['student_id']) for r in doris_records}
                
                # è¿‡æ»¤å‡ºçœŸæ­£çš„æ–°è®°å½•
                truly_new_records = []
                for record in new_records:
                    key = (record['snapshot_date'], record['student_id'])
                    if key not in doris_keys:
                        truly_new_records.append(record)
                
                return truly_new_records
            
            return []
        except Exception as e:
            logging.error(f"æ£€æµ‹æ–°æ•°æ®æ—¶å‡ºé”™: {e}")
            return []
    
    def get_doris_records_for_date(self, date):
        """è·å–Dorisä¸­æŒ‡å®šæ—¥æœŸçš„è®°å½•"""
        try:
            conn = self.get_doris_connection()
            cursor = conn.cursor(pymysql.cursors.DictCursor)
            
            sql = "SELECT snapshot_date, student_id FROM abc_warning WHERE snapshot_date >= %s"
            cursor.execute(sql, (date,))
            records = cursor.fetchall()
            cursor.close()
            conn.close()
            return records
        except Exception as e:
            logging.error(f"è·å–Dorisè®°å½•å¤±è´¥: {e}")
            return []
    
    def get_sync_stats(self):
        """è·å–åŒæ­¥ç»Ÿè®¡ä¿¡æ¯"""
        try:
            mysql_conn = self.get_mysql_connection()
            mysql_cursor = mysql_conn.cursor(pymysql.cursors.DictCursor)
            mysql_cursor.execute("SELECT COUNT(*) as count, MAX(snapshot_date) as latest FROM abc_warning")
            mysql_stats = mysql_cursor.fetchone()
            mysql_cursor.close()
            mysql_conn.close()
            
            doris_conn = self.get_doris_connection()
            doris_cursor = doris_conn.cursor(pymysql.cursors.DictCursor)
            doris_cursor.execute("SELECT COUNT(*) as count, MAX(snapshot_date) as latest FROM abc_warning")
            doris_stats = doris_cursor.fetchone()
            doris_cursor.close()
            doris_conn.close()
            
            return {
                'timestamp': datetime.now().isoformat(),
                'mysql': {
                    'count': mysql_stats['count'],
                    'latest_date': str(mysql_stats['latest']) if mysql_stats['latest'] else None
                },
                'doris': {
                    'count': doris_stats['count'],
                    'latest_date': str(doris_stats['latest']) if doris_stats['latest'] else None
                },
                'sync_lag_seconds': 0  # å®æ—¶åŒæ­¥ï¼Œå»¶è¿Ÿä¸º0
            }
        except Exception as e:
            logging.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def monitor_loop(self):
        """ä¸»ç›‘æ§å¾ªç¯"""
        logging.info(f"ğŸš€ å¯åŠ¨å®æ—¶åŒæ­¥ç›‘æ§ï¼Œæ£€æŸ¥é—´éš”: {self.check_interval}ç§’")
        
        while self.running:
            try:
                # æ£€æµ‹æ–°æ•°æ®
                new_records = self.detect_new_data()
                
                if new_records:
                    logging.info(f"ğŸ” æ£€æµ‹åˆ° {len(new_records)} æ¡æ–°æ•°æ®")
                    
                    # ç«‹å³åŒæ­¥åˆ°Doris
                    if self.sync_records_to_doris(new_records):
                        # è·å–å¹¶æ‰“å°åŒæ­¥çŠ¶æ€
                        stats = self.get_sync_stats()
                        if stats:
                            logging.info(f"ğŸ“Š åŒæ­¥çŠ¶æ€: MySQL({stats['mysql']['count']}) -> Doris({stats['doris']['count']})")
                    else:
                        logging.error("âŒ åŒæ­¥å¤±è´¥")
                
                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                time.sleep(self.check_interval)
                
            except KeyboardInterrupt:
                logging.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºç›‘æ§...")
                break
            except Exception as e:
                logging.error(f"ç›‘æ§å¾ªç¯å‡ºé”™: {e}")
                time.sleep(self.check_interval)
    
    def start(self):
        """å¯åŠ¨å®æ—¶ç›‘æ§"""
        if self.running:
            logging.warning("å®æ—¶ç›‘æ§å·²åœ¨è¿è¡Œä¸­")
            return
        
        self.running = True
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        monitor_thread = threading.Thread(target=self.monitor_loop)
        monitor_thread.daemon = True
        monitor_thread.start()
        
        logging.info("ğŸ‰ å®æ—¶åŒæ­¥ç›‘æ§å·²å¯åŠ¨ï¼")
        
        try:
            # ä¸»çº¿ç¨‹ä¿æŒè¿è¡Œï¼Œæ¯30ç§’æ‰“å°ä¸€æ¬¡çŠ¶æ€
            while self.running:
                time.sleep(30)
                stats = self.get_sync_stats()
                if stats:
                    print(f"\nğŸ“ˆ å®æ—¶åŒæ­¥çŠ¶æ€ ({datetime.now().strftime('%H:%M:%S')})")
                    print(f"   MySQL: {stats['mysql']['count']} æ¡è®°å½•")
                    print(f"   Doris: {stats['doris']['count']} æ¡è®°å½•")
                    print(f"   å»¶è¿Ÿ: < {self.check_interval} ç§’")
                    print("   çŠ¶æ€: ğŸŸ¢ å®æ—¶åŒæ­¥ä¸­...")
        except KeyboardInterrupt:
            self.stop()
    
    def stop(self):
        """åœæ­¢å®æ—¶ç›‘æ§"""
        self.running = False
        logging.info("ğŸ›‘ å®æ—¶åŒæ­¥ç›‘æ§å·²åœæ­¢")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description='MySQLåˆ°Doriså®æ—¶åŒæ­¥ç›‘æ§')
    parser.add_argument('--interval', type=int, default=1,
                        help='æ£€æŸ¥é—´éš”(ç§’)ï¼Œé»˜è®¤1ç§’')
    parser.add_argument('--test', action='store_true',
                        help='è¿è¡Œä¸€æ¬¡æµ‹è¯•æ£€æŸ¥')
    
    args = parser.parse_args()
    
    monitor = RealtimeSyncMonitor(args.interval)
    
    if args.test:
        # è¿è¡Œä¸€æ¬¡æµ‹è¯•
        logging.info("ğŸ§ª è¿è¡Œå®æ—¶åŒæ­¥æµ‹è¯•...")
        new_records = monitor.detect_new_data()
        if new_records:
            logging.info(f"æ£€æµ‹åˆ° {len(new_records)} æ¡æ–°æ•°æ®")
            monitor.sync_records_to_doris(new_records)
        else:
            logging.info("æ²¡æœ‰æ£€æµ‹åˆ°æ–°æ•°æ®")
        
        # æ‰“å°çŠ¶æ€
        stats = monitor.get_sync_stats()
        if stats:
            print(json.dumps(stats, indent=2, ensure_ascii=False))
    else:
        # å¯åŠ¨æŒç»­ç›‘æ§
        print("ğŸš€ å¯åŠ¨MySQLåˆ°Doriså®æ—¶åŒæ­¥ç›‘æ§")
        print(f"ğŸ“Š ç›‘æ§é—´éš”: {args.interval} ç§’")
        print("ğŸ”„ å®ç°æ¯«ç§’çº§æ•°æ®åŒæ­¥")
        print("ğŸ“± æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        print("=" * 50)
        
        monitor.start()

if __name__ == '__main__':
    main() 