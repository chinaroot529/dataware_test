#!/usr/bin/env python3
"""
é—­ç¯éªŒè¯ç³»ç»Ÿ - å®Œæ•´ç‰ˆ
====================
* ä»å­¦ç§‘ç½‘è·å–æ–°é¢˜ â†’ æŒä¹…åŒ–åˆ°æ•°æ®é›† â†’ å¢é‡æ›´æ–°æ¨¡å‹ â†’ éªŒè¯ç®—æ³•
* è§£å†³tokenæµªè´¹é—®é¢˜ï¼Œå®ç°çœŸæ­£çš„æ•°æ®ç§¯ç´¯å’Œæ¨¡å‹å¢é•¿
* æ”¯æŒç‰ˆæœ¬ç®¡ç†å’Œå¢é‡ç»Ÿè®¡

ä½¿ç”¨æ–¹æ³•:
    python closed_loop_validation.py questions.csv --iterations 5
"""

import argparse
import pathlib
import json
import time
from datetime import datetime
from typing import Dict, List

from train_ultimate_model import pipeline as validation_pipeline, load_csv
from question_similarity_recommender import QuestionSimilarityRecommender

class ClosedLoopValidator:
    """å®Œæ•´çš„é—­ç¯éªŒè¯ç³»ç»Ÿ"""
    
    def __init__(self, base_dataset: str, api_key: str = None):
        self.base_dataset = pathlib.Path(base_dataset)
        self.api_key = api_key
        self.stats = {
            "start_time": datetime.now().isoformat(),
            "iterations": 0,
            "total_new_questions": 0,
            "total_api_calls": 0,
            "successful_matches": 0,
            "dataset_growth": []
        }
        
    def run_iteration(self, iteration: int) -> Dict:
        """è¿è¡Œä¸€æ¬¡å®Œæ•´çš„éªŒè¯è¿­ä»£"""
        print(f"\n{'='*60}")
        print(f"ğŸ”„  ITERATION {iteration + 1}")
        print(f"{'='*60}")
        
        iteration_start = time.time()
        
        # 1. ç¡®å®šå½“å‰æ•°æ®é›†è·¯å¾„
        if iteration == 0:
            current_dataset = self.base_dataset
        else:
            # ä½¿ç”¨ä¸Šä¸€æ¬¡enrichedçš„ç»“æœ
            current_dataset = self.base_dataset.parent / f"{self.base_dataset.stem}_enriched.csv"
            
        if not current_dataset.exists():
            current_dataset = self.base_dataset
            
        print(f"ğŸ“‚  Using dataset: {current_dataset}")
        
        # 2. è®°å½•å½“å‰æ•°æ®é›†å¤§å°
        df_before = load_csv(current_dataset)
        count_before = len(df_before)
        
        # 3. è¿è¡ŒéªŒè¯pipelineï¼ˆä¼šè‡ªåŠ¨ä¿å­˜enrichedç‰ˆæœ¬ï¼‰
        try:
            validation_pipeline(current_dataset, save_enriched=True)
            self.stats["total_api_calls"] += 1
            
            # 4. æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ•°æ®
            enriched_path = current_dataset.parent / f"{current_dataset.stem}_enriched.csv"
            if enriched_path.exists():
                df_after = load_csv(enriched_path)
                count_after = len(df_after)
                new_questions = count_after - count_before
                
                if new_questions > 0:
                    self.stats["total_new_questions"] += new_questions
                    print(f"ğŸ“ˆ  Dataset grew by {new_questions} questions")
                    
                    # 5. æ›´æ–°æ¨èæ¨¡å‹ï¼ˆå¦‚æœæœ‰ç°æœ‰æ¨¡å‹çš„è¯ï¼‰
                    self._update_recommender_model(enriched_path)
                else:
                    print("ğŸ“Š  No new questions added this iteration")
                    
                # è®°å½•å¢é•¿ç»Ÿè®¡
                self.stats["dataset_growth"].append({
                    "iteration": iteration + 1,
                    "before": count_before,
                    "after": count_after,
                    "added": new_questions,
                    "timestamp": datetime.now().isoformat()
                })
                
            iteration_time = time.time() - iteration_start
            print(f"â±ï¸  Iteration completed in {iteration_time:.1f}s")
            
            return {
                "success": True,
                "new_questions": new_questions,
                "time_taken": iteration_time
            }
            
        except Exception as e:
            print(f"âŒ  Iteration failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "time_taken": time.time() - iteration_start
            }
    
    def _update_recommender_model(self, enriched_path: pathlib.Path):
        """æ›´æ–°æ¨èæ¨¡å‹ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰"""
        model_files = [
            "question_sim.feather",
            "question_sim_emb.npy", 
            "question_sim.faiss"
        ]
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨é¢„è®­ç»ƒæ¨¡å‹
        if all((self.base_dataset.parent / f).exists() for f in model_files):
            try:
                print("ğŸ”„  Updating existing recommender model...")
                recommender = QuestionSimilarityRecommender(
                    csv_path=str(self.base_dataset), 
                    api_key=self.api_key
                )
                
                # åŠ è½½ç°æœ‰æ¨¡å‹
                recommender.load("question_sim")
                
                # å¢é‡æ›´æ–°
                added = recommender.update_from_csv(str(enriched_path), update_files=True)
                if added > 0:
                    print(f"âœ…  Model updated with {added} new questions")
                else:
                    print("â„¹ï¸  No new questions to add to model")
                    
            except Exception as e:
                print(f"âš ï¸  Failed to update recommender model: {e}")
        else:
            print("â„¹ï¸  No existing model found, skipping model update")
    
    def run_multiple_iterations(self, num_iterations: int = 3, delay_between: int = 2):
        """è¿è¡Œå¤šæ¬¡è¿­ä»£"""
        print(f"ğŸš€  Starting closed-loop validation with {num_iterations} iterations")
        print(f"ğŸ“Š  Base dataset: {self.base_dataset}")
        print(f"â±ï¸  Delay between iterations: {delay_between}s")
        
        results = []
        
        for i in range(num_iterations):
            result = self.run_iteration(i)
            results.append(result)
            self.stats["iterations"] += 1
            
            if result["success"]:
                self.stats["successful_matches"] += 1
                
            # å»¶è¿Ÿï¼ˆé¿å…APIé™åˆ¶ï¼‰
            if i < num_iterations - 1:
                print(f"â¸ï¸  Waiting {delay_between}s before next iteration...")
                time.sleep(delay_between)
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self._generate_report(results)
        
        return results
    
    def _generate_report(self, results: List[Dict]):
        """ç”Ÿæˆæœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š"""
        self.stats["end_time"] = datetime.now().isoformat()
        self.stats["total_time"] = sum(r.get("time_taken", 0) for r in results)
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š  FINAL REPORT")
        print(f"{'='*60}")
        print(f"ğŸ”¢  Total iterations: {self.stats['iterations']}")
        print(f"âœ…  Successful iterations: {self.stats['successful_matches']}")
        print(f"ğŸ“ˆ  Total new questions discovered: {self.stats['total_new_questions']}")
        print(f"ğŸŒ  Total API calls made: {self.stats['total_api_calls']}")
        print(f"â±ï¸  Total time: {self.stats['total_time']:.1f}s")
        
        if self.stats["total_new_questions"] > 0:
            avg_new_per_iteration = self.stats["total_new_questions"] / self.stats["iterations"]
            print(f"ğŸ“Š  Average new questions per iteration: {avg_new_per_iteration:.1f}")
            
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_path = self.base_dataset.parent / f"closed_loop_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump({
                "stats": self.stats,
                "iteration_results": results
            }, f, ensure_ascii=False, indent=2)
            
        print(f"ğŸ“„  Detailed report saved to: {report_path}")
        
        # æ•°æ®é›†å¢é•¿å¯è§†åŒ–
        if self.stats["dataset_growth"]:
            print(f"\nğŸ“ˆ  Dataset Growth Timeline:")
            for growth in self.stats["dataset_growth"]:
                print(f"    Iteration {growth['iteration']}: {growth['before']} â†’ {growth['after']} (+{growth['added']})")

def main():
    parser = argparse.ArgumentParser(description="Closed-loop validation system")
    parser.add_argument("dataset", help="Base dataset CSV file")
    parser.add_argument("--iterations", "-n", type=int, default=3, 
                       help="Number of validation iterations (default: 3)")
    parser.add_argument("--delay", "-d", type=int, default=2,
                       help="Delay between iterations in seconds (default: 2)")
    parser.add_argument("--api-key", help="OpenAI API key (or set OPENAI_API_KEY env var)")
    
    args = parser.parse_args()
    
    validator = ClosedLoopValidator(args.dataset, args.api_key)
    results = validator.run_multiple_iterations(args.iterations, args.delay)
    
    # ç®€å•çš„æˆåŠŸ/å¤±è´¥ç»Ÿè®¡
    successful = sum(1 for r in results if r["success"])
    print(f"\nğŸ¯  Final Success Rate: {successful}/{len(results)} ({successful/len(results)*100:.1f}%)")

if __name__ == "__main__":
    main()
