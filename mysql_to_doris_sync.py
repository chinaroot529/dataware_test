#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MySQLåˆ°Dorisæ•°æ®åŒæ­¥å·¥å…·
åŠŸèƒ½ï¼š
1. å…¨é‡å¯¼å…¥MySQLè¡¨åˆ°Doris
2. è®¾ç½®CDCå¢é‡åŒæ­¥
"""

import pymysql
import pandas as pd
import requests
import json
import time
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MySQLToDorisSync:
    def __init__(self):
        # MySQLé…ç½®
        self.mysql_config = {
            'host': '10.10.0.117',
            'port': 6033,
            'user': 'root',
            'password': 'Xml123&45!',
            'database': 'data_ware_test',
            'charset': 'utf8mb4'
        }
        
        # Dorisé…ç½®ï¼ˆè¿œç¨‹æœåŠ¡å™¨ï¼‰
        self.doris_config = {
            'fe_host': '192.168.99.6',
            'fe_http_port': 18030,  # å¯¹åº”docker.ymlä¸­çš„ç«¯å£æ˜ å°„
            'fe_query_port': 19030,  # MySQLåè®®ç«¯å£
            'username': 'root',
            'password': '',  # Dorisé»˜è®¤rootç”¨æˆ·æ— å¯†ç 
            'database': 'ods'  # æ•°æ®ä»“åº“ODSå±‚
        }
        
    def connect_mysql(self):
        """è¿æ¥MySQLæ•°æ®åº“"""
        try:
            conn = pymysql.connect(**self.mysql_config)
            logger.info("MySQLè¿æ¥æˆåŠŸ")
            return conn
        except Exception as e:
            logger.error(f"MySQLè¿æ¥å¤±è´¥: {e}")
            return None
    
    def connect_doris(self):
        """è¿æ¥Dorisæ•°æ®åº“"""
        try:
            import pymysql
            conn = pymysql.connect(
                host=self.doris_config['fe_host'],
                port=self.doris_config['fe_query_port'],
                user=self.doris_config['username'],
                password=self.doris_config['password'],
                charset='utf8mb4'
            )
            logger.info("Dorisè¿æ¥æˆåŠŸ")
            return conn
        except Exception as e:
            logger.error(f"Dorisè¿æ¥å¤±è´¥: {e}")
            return None
    
    def get_table_schema(self, table_name):
        """è·å–MySQLè¡¨ç»“æ„"""
        mysql_conn = self.connect_mysql()
        if not mysql_conn:
            return None
            
        try:
            cursor = mysql_conn.cursor(pymysql.cursors.DictCursor)
            cursor.execute(f"DESCRIBE {table_name}")
            schema = cursor.fetchall()
            
            cursor.execute(f"SELECT COUNT(*) as count FROM {table_name}")
            count = cursor.fetchone()['count']
            
            logger.info(f"è¡¨ {table_name} ç»“æ„è·å–æˆåŠŸï¼Œå…± {count} æ¡è®°å½•")
            return schema, count
        except Exception as e:
            logger.error(f"è·å–è¡¨ç»“æ„å¤±è´¥: {e}")
            return None, 0
        finally:
            mysql_conn.close()
    
    def mysql_to_doris_type(self, mysql_type):
        """MySQLæ•°æ®ç±»å‹è½¬æ¢ä¸ºDorisæ•°æ®ç±»å‹"""
        type_mapping = {
            'int': 'INT',
            'bigint': 'BIGINT',
            'varchar': 'VARCHAR',
            'text': 'TEXT',
            'datetime': 'DATETIME',
            'timestamp': 'DATETIME',
            'date': 'DATE',
            'decimal': 'DECIMAL',
            'float': 'FLOAT',
            'double': 'DOUBLE',
            'tinyint': 'TINYINT',
            'smallint': 'SMALLINT',
            'mediumint': 'INT',
            'longtext': 'TEXT',
            'json': 'JSON'
        }
        
        # æå–åŸºç¡€ç±»å‹å
        base_type = mysql_type.split('(')[0].lower()
        return type_mapping.get(base_type, 'VARCHAR(500)')
    
    def create_doris_table(self, table_name, mysql_schema):
        """åœ¨Dorisä¸­åˆ›å»ºå¯¹åº”çš„è¡¨"""
        doris_conn = self.connect_doris()
        if not doris_conn:
            return False
            
        try:
            cursor = doris_conn.cursor()
            
            # åˆ›å»ºæ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            cursor.execute(f"CREATE DATABASE IF NOT EXISTS {self.doris_config['database']}")
            cursor.execute(f"USE {self.doris_config['database']}")
            
            # æ„å»ºCREATE TABLEè¯­å¥
            columns = []
            key_columns = []
            
            for field in mysql_schema:
                field_name = field['Field']
                mysql_type = field['Type']
                is_null = field['Null'] == 'YES'
                is_key = field['Key'] in ('PRI', 'UNI')
                
                doris_type = self.mysql_to_doris_type(mysql_type)
                
                # å¤„ç†VARCHARé•¿åº¦
                if 'varchar' in mysql_type.lower():
                    doris_type = mysql_type.upper().replace('VARCHAR', 'VARCHAR')
                
                null_str = '' if is_null else ' NOT NULL'
                columns.append(f"`{field_name}` {doris_type}{null_str}")
                
                if is_key:
                    key_columns.append(f"`{field_name}`")
            
            # å¦‚æœæ²¡æœ‰ä¸»é”®ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå­—æ®µä½œä¸ºkey
            if not key_columns and columns:
                first_field = mysql_schema[0]['Field']
                key_columns.append(f"`{first_field}`")
            
            create_sql = f"""
CREATE TABLE IF NOT EXISTS `{table_name}` (
{', '.join(columns)}
) DUPLICATE KEY({', '.join(key_columns)})
DISTRIBUTED BY HASH({', '.join(key_columns)}) BUCKETS 10
PROPERTIES (
    "replication_allocation" = "tag.location.default: 1"
)
"""
            
            logger.info(f"åˆ›å»ºDorisè¡¨SQL: {create_sql}")
            cursor.execute(create_sql)
            logger.info(f"Dorisè¡¨ {table_name} åˆ›å»ºæˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºDorisè¡¨å¤±è´¥: {e}")
            return False
        finally:
            doris_conn.close()
    
    def full_import_data(self, table_name, batch_size=1000):
        """å…¨é‡å¯¼å…¥æ•°æ®"""
        mysql_conn = self.connect_mysql()
        doris_conn = self.connect_doris()
        
        if not mysql_conn or not doris_conn:
            return False
            
        try:
            # ä½¿ç”¨pandasåˆ†æ‰¹è¯»å–MySQLæ•°æ®
            mysql_cursor = mysql_conn.cursor(pymysql.cursors.DictCursor)
            mysql_cursor.execute(f"SELECT COUNT(*) as total FROM {table_name}")
            total_rows = mysql_cursor.fetchone()['total']
            
            logger.info(f"å¼€å§‹å…¨é‡å¯¼å…¥ {table_name}ï¼Œæ€»è®¡ {total_rows} æ¡è®°å½•")
            
            doris_cursor = doris_conn.cursor()
            doris_cursor.execute(f"USE {self.doris_config['database']}")
            
            # åˆ†æ‰¹å¤„ç†
            offset = 0
            imported_rows = 0
            
            while offset < total_rows:
                # è¯»å–ä¸€æ‰¹æ•°æ®
                mysql_cursor.execute(f"""
                    SELECT * FROM {table_name} 
                    LIMIT {batch_size} OFFSET {offset}
                """)
                batch_data = mysql_cursor.fetchall()
                
                if not batch_data:
                    break
                
                # æ„å»ºINSERTè¯­å¥
                if batch_data:
                    columns = list(batch_data[0].keys())
                    placeholders = ', '.join(['%s'] * len(columns))
                    insert_sql = f"""
                        INSERT INTO {table_name} ({', '.join(f'`{col}`' for col in columns)}) 
                        VALUES ({placeholders})
                    """
                    
                    # å‡†å¤‡æ•°æ®
                    values = []
                    for row in batch_data:
                        row_values = []
                        for col in columns:
                            value = row[col]
                            if isinstance(value, datetime):
                                value = value.strftime('%Y-%m-%d %H:%M:%S')
                            row_values.append(value)
                        values.append(tuple(row_values))
                    
                    # æ‰¹é‡æ’å…¥
                    doris_cursor.executemany(insert_sql, values)
                    imported_rows += len(batch_data)
                    
                    logger.info(f"å·²å¯¼å…¥ {imported_rows}/{total_rows} æ¡è®°å½•")
                
                offset += batch_size
                
            logger.info(f"å…¨é‡å¯¼å…¥å®Œæˆï¼Œå…±å¯¼å…¥ {imported_rows} æ¡è®°å½•")
            return True
            
        except Exception as e:
            logger.error(f"å…¨é‡å¯¼å…¥å¤±è´¥: {e}")
            return False
        finally:
            if mysql_conn:
                mysql_conn.close()
            if doris_conn:
                doris_conn.close()
    
    def setup_cdc_sync(self, table_name):
        """è®¾ç½®CDCå¢é‡åŒæ­¥ï¼ˆä½¿ç”¨Flink CDCï¼‰"""
        # è¿™é‡Œæä¾›CDCè®¾ç½®çš„é…ç½®å»ºè®®
        cdc_config = {
            "flink_sql": f"""
            -- åˆ›å»ºMySQL CDCæºè¡¨
            CREATE TABLE mysql_{table_name}_source (
                -- è¿™é‡Œéœ€è¦æ ¹æ®å®é™…è¡¨ç»“æ„å¡«å†™å­—æ®µ
            ) WITH (
                'connector' = 'mysql-cdc',
                'hostname' = '{self.mysql_config['host']}',
                'port' = '{self.mysql_config['port']}',
                'username' = '{self.mysql_config['user']}',
                'password' = '{self.mysql_config['password']}',
                'database-name' = '{self.mysql_config['database']}',
                'table-name' = '{table_name}'
            );
            
            -- åˆ›å»ºDoris sinkè¡¨
            CREATE TABLE doris_{table_name}_sink (
                -- è¿™é‡Œéœ€è¦æ ¹æ®å®é™…è¡¨ç»“æ„å¡«å†™å­—æ®µ
            ) WITH (
                'connector' = 'doris',
                'fenodes' = '{self.doris_config['fe_host']}:{self.doris_config['fe_http_port']}',
                'table.identifier' = '{self.doris_config['database']}.{table_name}',
                'username' = '{self.doris_config['username']}',
                'password' = '{self.doris_config['password']}'
            );
            
            -- å¯åŠ¨CDCåŒæ­¥
            INSERT INTO doris_{table_name}_sink SELECT * FROM mysql_{table_name}_source;
            """
        }
        
        logger.info("CDCé…ç½®ç”Ÿæˆå®Œæˆï¼Œéœ€è¦åœ¨Flinkä¸­æ‰§è¡Œä»¥ä¸‹SQL:")
        logger.info(cdc_config["flink_sql"])
        
        return cdc_config
    
    def sync_table(self, table_name):
        """åŒæ­¥æŒ‡å®šè¡¨çš„å®Œæ•´æµç¨‹"""
        logger.info(f"å¼€å§‹åŒæ­¥è¡¨: {table_name}")
        
        # 1. è·å–è¡¨ç»“æ„
        schema, row_count = self.get_table_schema(table_name)
        if not schema:
            logger.error("è·å–è¡¨ç»“æ„å¤±è´¥")
            return False
        
        # 2. åœ¨Dorisä¸­åˆ›å»ºè¡¨
        if not self.create_doris_table(table_name, schema):
            logger.error("åˆ›å»ºDorisè¡¨å¤±è´¥")
            return False
        
        # 3. å…¨é‡å¯¼å…¥æ•°æ®
        if not self.full_import_data(table_name):
            logger.error("å…¨é‡å¯¼å…¥å¤±è´¥")
            return False
        
        # 4. è®¾ç½®CDCé…ç½®
        cdc_config = self.setup_cdc_sync(table_name)
        
        logger.info(f"è¡¨ {table_name} åŒæ­¥è®¾ç½®å®Œæˆ")
        return True

def main():
    """ä¸»å‡½æ•°"""
    sync_tool = MySQLToDorisSync()
    table_name = "abc_warning"
    
    # æ‰§è¡ŒåŒæ­¥
    success = sync_tool.sync_table(table_name)
    
    if success:
        print(f"\nâœ… è¡¨ {table_name} åŒæ­¥è®¾ç½®æˆåŠŸ!")
        print("\nğŸ“‹ åç»­æ­¥éª¤:")
        print("1. å…¨é‡æ•°æ®å·²å¯¼å…¥Doris")
        print("2. è¯·åœ¨Flinkä¸­æ‰§è¡Œç”Ÿæˆçš„CDC SQLé…ç½®")
        print("3. éªŒè¯å¢é‡åŒæ­¥æ˜¯å¦æ­£å¸¸å·¥ä½œ")
    else:
        print(f"\nâŒ è¡¨ {table_name} åŒæ­¥è®¾ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

if __name__ == "__main__":
    main() 